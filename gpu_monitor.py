#!/usr/bin/env python3
"""
GPUç›‘æµ‹è„šæœ¬ - è‡ªåŠ¨æ£€æµ‹ç©ºé—²GPUå¹¶è¿è¡Œè®­ç»ƒä»»åŠ¡
å½“æ£€æµ‹åˆ°ç©ºé—²GPUæ—¶ï¼Œè‡ªåŠ¨å¯åŠ¨æŒ‡å®šçš„è®­ç»ƒå‘½ä»¤
"""

import subprocess
import time
import logging
import argparse
import os
import signal
import sys
from typing import List, Dict, Optional
import json

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('gpu_monitor.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class GPUMonitor:
    def __init__(self, 
                 check_interval: int = 60,
                 gpu_memory_threshold: int = 1000,
                 max_concurrent_tasks: int = 2):
        """
        åˆå§‹åŒ–GPUç›‘æµ‹å™¨
        
        Args:
            check_interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
            gpu_memory_threshold: GPUå†…å­˜é˜ˆå€¼ï¼ˆMBï¼‰ï¼Œä½äºæ­¤å€¼è®¤ä¸ºGPUç©ºé—²
            max_concurrent_tasks: æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°
        """
        self.check_interval = check_interval
        self.gpu_memory_threshold = gpu_memory_threshold
        self.max_concurrent_tasks = max_concurrent_tasks
        self.running_tasks: List[Dict] = []
        self.task_queue = [
            {
                "name": "ResNetCRNN",
                "command": ["python", "train.py", "--model", "ResNetCRNN", 
                           "--config", "configs/ResNetCRNN_train.yaml"],
                "status": "pending"
            },
            {
                "name": "SwinTransformer-RNN (Resume)",
                "command": ["python", "train.py", "--model", "swintransformer-RNN", 
                           "--config", "configs/swintransformer-RNN_train.yaml", "--resume", "50"],
                "status": "pending"
            }
        ]
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self.signal_handler)
        signal.signal(signal.SIGTERM, self.signal_handler)
        
        logger.info(f"GPUç›‘æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"æ£€æŸ¥é—´éš”: {check_interval}ç§’")
        logger.info(f"GPUå†…å­˜é˜ˆå€¼: {gpu_memory_threshold}MB")
        logger.info(f"æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°: {max_concurrent_tasks}")
        logger.info(f"å¾…æ‰§è¡Œä»»åŠ¡æ•°: {len(self.task_queue)}")

    def signal_handler(self, signum, frame):
        """å¤„ç†é€€å‡ºä¿¡å·"""
        logger.info(f"æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨ä¼˜é›…é€€å‡º...")
        self.cleanup()
        sys.exit(0)

    def get_gpu_info(self) -> List[Dict]:
        """
        è·å–GPUä¿¡æ¯
        
        Returns:
            GPUä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸ªGPUåŒ…å«id, memory_used, memory_total, utilizationç­‰ä¿¡æ¯
        """
        try:
            # ä½¿ç”¨gpustatè·å–GPUä¿¡æ¯ï¼ˆJSONæ ¼å¼æ›´å¯é ï¼‰
            result = subprocess.run(
                ["gpustat", "--json"],
                capture_output=True, text=True, timeout=10
            )
            
            if result.returncode != 0:
                logger.error(f"gpustatæ‰§è¡Œå¤±è´¥: {result.stderr}")
                return []
            
            # è§£æJSONè¾“å‡º
            data = json.loads(result.stdout)
            gpu_info = []
            
            for gpu in data.get("gpus", []):
                gpu_id = gpu.get("index", 0)
                memory_used = gpu.get("memory.used", 0)
                memory_total = gpu.get("memory.total", 0)
                utilization = gpu.get("utilization.gpu", 0)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰è¿›ç¨‹åœ¨è¿è¡Œ
                has_processes = len(gpu.get("processes", [])) > 0
                
                gpu_info.append({
                    "id": gpu_id,
                    "memory_used": memory_used,
                    "memory_total": memory_total,
                    "utilization": utilization,
                    "has_processes": has_processes,
                    "is_idle": memory_used < self.gpu_memory_threshold and utilization < 10 and not has_processes
                })
            
            return gpu_info
            
        except subprocess.TimeoutExpired:
            logger.error("gpustatæ‰§è¡Œè¶…æ—¶")
            return []
        except json.JSONDecodeError as e:
            logger.error(f"è§£ægpustat JSONè¾“å‡ºå¤±è´¥: {e}")
            return []
        except Exception as e:
            logger.error(f"è·å–GPUä¿¡æ¯å¤±è´¥: {e}")
            return []

    def find_idle_gpu(self) -> Optional[int]:
        """
        æŸ¥æ‰¾ç©ºé—²çš„GPU
        
        Returns:
            ç©ºé—²GPUçš„IDï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›None
        """
        gpu_info = self.get_gpu_info()
        if not gpu_info:
            return None
            
        for gpu in gpu_info:
            if gpu["is_idle"]:
                logger.info(f"æ‰¾åˆ°ç©ºé—²GPU {gpu['id']}: "
                          f"å†…å­˜ä½¿ç”¨ {gpu['memory_used']}/{gpu['memory_total']}MB, "
                          f"åˆ©ç”¨ç‡ {gpu['utilization']}%")
                return gpu["id"]
        
        return None

    def start_training_task(self, gpu_id: int, task: Dict) -> bool:
        """
        åœ¨æŒ‡å®šGPUä¸Šå¯åŠ¨è®­ç»ƒä»»åŠ¡
        
        Args:
            gpu_id: GPU ID
            task: ä»»åŠ¡ä¿¡æ¯
            
        Returns:
            æ˜¯å¦æˆåŠŸå¯åŠ¨
        """
        try:
            # è®¾ç½®ç¯å¢ƒå˜é‡æŒ‡å®šGPU
            env = os.environ.copy()
            env["CUDA_VISIBLE_DEVICES"] = str(gpu_id)
            
            # å¯åŠ¨è®­ç»ƒè¿›ç¨‹
            process = subprocess.Popen(
                task["command"],
                env=env,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )
            
            # è®°å½•ä»»åŠ¡ä¿¡æ¯
            task_info = {
                "name": task["name"],
                "gpu_id": gpu_id,
                "pid": process.pid,
                "process": process,
                "start_time": time.time(),
                "command": " ".join(task["command"])
            }
            
            self.running_tasks.append(task_info)
            task["status"] = "running"
            
            logger.info(f"âœ… å¯åŠ¨ä»»åŠ¡ '{task['name']}' åœ¨GPU {gpu_id} (PID: {process.pid})")
            logger.info(f"å‘½ä»¤: {' '.join(task['command'])}")
            
            return True
            
        except Exception as e:
            logger.error(f"å¯åŠ¨ä»»åŠ¡ '{task['name']}' å¤±è´¥: {e}")
            return False

    def check_running_tasks(self):
        """æ£€æŸ¥è¿è¡Œä¸­çš„ä»»åŠ¡çŠ¶æ€"""
        completed_tasks = []
        
        for task in self.running_tasks:
            process = task["process"]
            
            # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ
            if process.poll() is None:
                # è¿›ç¨‹è¿˜åœ¨è¿è¡Œ
                continue
            
            # è¿›ç¨‹å·²ç»“æŸ
            return_code = process.returncode
            stdout, stderr = process.communicate()
            
            if return_code == 0:
                logger.info(f"âœ… ä»»åŠ¡ '{task['name']}' åœ¨GPU {task['gpu_id']} å®Œæˆ")
            else:
                logger.error(f"âŒ ä»»åŠ¡ '{task['name']}' åœ¨GPU {task['gpu_id']} å¤±è´¥ (è¿”å›ç : {return_code})")
                if stderr:
                    logger.error(f"é”™è¯¯è¾“å‡º: {stderr}")
            
            completed_tasks.append(task)
            
            # å°†ä»»åŠ¡çŠ¶æ€é‡ç½®ä¸ºpendingï¼Œä»¥ä¾¿é‡æ–°æ‰§è¡Œ
            for queued_task in self.task_queue:
                if queued_task["name"] == task["name"]:
                    queued_task["status"] = "pending"
                    break
        
        # ç§»é™¤å·²å®Œæˆçš„ä»»åŠ¡
        for task in completed_tasks:
            self.running_tasks.remove(task)

    def run(self):
        """ä¸»è¿è¡Œå¾ªç¯"""
        logger.info("ğŸš€ GPUç›‘æµ‹å™¨å¼€å§‹è¿è¡Œ...")
        
        try:
            while True:
                # æ£€æŸ¥è¿è¡Œä¸­çš„ä»»åŠ¡çŠ¶æ€
                self.check_running_tasks()
                
                # å¦‚æœæœ‰ç©ºé—²GPUä¸”æœ‰å¾…æ‰§è¡Œçš„ä»»åŠ¡
                if len(self.running_tasks) < self.max_concurrent_tasks:
                    idle_gpu = self.find_idle_gpu()
                    
                    if idle_gpu is not None:
                        # æŸ¥æ‰¾å¾…æ‰§è¡Œçš„ä»»åŠ¡
                        for task in self.task_queue:
                            if task["status"] == "pending":
                                if self.start_training_task(idle_gpu, task):
                                    break  # ä¸€æ¬¡åªå¯åŠ¨ä¸€ä¸ªä»»åŠ¡
                
                # æ˜¾ç¤ºå½“å‰çŠ¶æ€
                self.show_status()
                
                # ç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥
                time.sleep(self.check_interval)
                
        except KeyboardInterrupt:
            logger.info("æ”¶åˆ°é”®ç›˜ä¸­æ–­ï¼Œæ­£åœ¨é€€å‡º...")
        except Exception as e:
            logger.error(f"è¿è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        finally:
            self.cleanup()

    def show_status(self):
        """æ˜¾ç¤ºå½“å‰çŠ¶æ€"""
        logger.info(f"ğŸ“Š çŠ¶æ€æ›´æ–° - è¿è¡Œä¸­ä»»åŠ¡: {len(self.running_tasks)}/{self.max_concurrent_tasks}, "
                   f"å¾…æ‰§è¡Œä»»åŠ¡: {len([t for t in self.task_queue if t['status'] == 'pending'])}")
        
        if self.running_tasks:
            for task in self.running_tasks:
                runtime = time.time() - task["start_time"]
                logger.info(f"  ğŸ”„ {task['name']} åœ¨GPU {task['gpu_id']} è¿è¡Œä¸­ (PID: {task['pid']}, è¿è¡Œæ—¶é—´: {runtime:.0f}s)")

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        logger.info("ğŸ§¹ æ­£åœ¨æ¸…ç†èµ„æº...")
        
        # ç»ˆæ­¢æ‰€æœ‰è¿è¡Œä¸­çš„ä»»åŠ¡
        for task in self.running_tasks:
            try:
                process = task["process"]
                if process.poll() is None:
                    logger.info(f"ç»ˆæ­¢ä»»åŠ¡ '{task['name']}' (PID: {task['pid']})")
                    process.terminate()
                    
                    # ç­‰å¾…è¿›ç¨‹ç»“æŸ
                    try:
                        process.wait(timeout=10)
                    except subprocess.TimeoutExpired:
                        logger.warning(f"å¼ºåˆ¶ç»ˆæ­¢ä»»åŠ¡ '{task['name']}' (PID: {task['pid']})")
                        process.kill()
                        
            except Exception as e:
                logger.error(f"æ¸…ç†ä»»åŠ¡ '{task['name']}' æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        
        logger.info("âœ… èµ„æºæ¸…ç†å®Œæˆ")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="GPUç›‘æµ‹è„šæœ¬ - è‡ªåŠ¨è¿è¡Œè®­ç»ƒä»»åŠ¡")
    parser.add_argument("--check-interval", type=int, default=60,
                       help="æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼Œé»˜è®¤60ï¼‰")
    parser.add_argument("--gpu-memory-threshold", type=int, default=1000,
                       help="GPUå†…å­˜é˜ˆå€¼ï¼ˆMBï¼Œé»˜è®¤1000ï¼‰")
    parser.add_argument("--max-concurrent-tasks", type=int, default=2,
                       help="æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°ï¼ˆé»˜è®¤2ï¼‰")
    parser.add_argument("--dry-run", action="store_true",
                       help="è¯•è¿è¡Œæ¨¡å¼ï¼Œä¸å®é™…å¯åŠ¨ä»»åŠ¡")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥gpustatæ˜¯å¦å¯ç”¨
    try:
        subprocess.run(["gpustat", "--version"], 
                      capture_output=True, check=True, timeout=5)
    except (subprocess.CalledProcessError, subprocess.TimeoutExpired, FileNotFoundError):
        logger.error("âŒ gpustatä¸å¯ç”¨ï¼Œè¯·å…ˆå®‰è£…gpustat")
        logger.error("å®‰è£…å‘½ä»¤: pip install gpustat")
        logger.error("æˆ–è€…: conda install -c conda-forge gpustat")
        sys.exit(1)
    
    # æ£€æŸ¥è®­ç»ƒè„šæœ¬æ˜¯å¦å­˜åœ¨
    if not os.path.exists("train.py"):
        logger.error("âŒ train.pyä¸å­˜åœ¨ï¼Œè¯·ç¡®ä¿åœ¨æ­£ç¡®çš„ç›®å½•ä¸­è¿è¡Œ")
        sys.exit(1)
    
    if not os.path.exists("configs/ResNetCRNN_train.yaml"):
        logger.error("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·ç¡®ä¿åœ¨æ­£ç¡®çš„ç›®å½•ä¸­è¿è¡Œ")
        sys.exit(1)
    
    # åˆ›å»ºå¹¶è¿è¡ŒGPUç›‘æµ‹å™¨
    monitor = GPUMonitor(
        check_interval=args.check_interval,
        gpu_memory_threshold=args.gpu_memory_threshold,
        max_concurrent_tasks=args.max_concurrent_tasks
    )
    
    if args.dry_run:
        logger.info("ğŸ” è¯•è¿è¡Œæ¨¡å¼ - æ˜¾ç¤ºGPUä¿¡æ¯ä½†ä¸å¯åŠ¨ä»»åŠ¡")
        gpu_info = monitor.get_gpu_info()
        if gpu_info:
            logger.info("GPUä¿¡æ¯:")
            for gpu in gpu_info:
                status = "ç©ºé—²" if gpu["is_idle"] else "å¿™ç¢Œ"
                logger.info(f"  GPU {gpu['id']}: {status} "
                          f"(å†…å­˜: {gpu['memory_used']}/{gpu['memory_total']}MB, "
                          f"åˆ©ç”¨ç‡: {gpu['utilization']}%)")
        else:
            logger.warning("æ— æ³•è·å–GPUä¿¡æ¯")
    else:
        monitor.run()

if __name__ == "__main__":
    main()
